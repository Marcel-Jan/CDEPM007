{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise file formats speed comparison in Spark 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Spark session\n",
    "\n",
    "\n",
    "\n",
    "https://spark.apache.org/docs/latest/sql-getting-started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data into dataframe and inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---------------------+-------+--------------------+\n",
      "| id|name|number_family_members|country|               Covid|\n",
      "+---+----+---------------------+-------+--------------------+\n",
      "|  0|   1|        Crystal Smith|      3|   Equatorial Guinea|\n",
      "|  1|   2|      Bradley Walters|      2|                Mali|\n",
      "|  2|   3|           Chad Gross|      3|        Burkina Faso|\n",
      "|  3|   4|        Kathryn Smith|      3|             Moldova|\n",
      "|  4|   5|          Sarah Stout|      5|             Moldova|\n",
      "|  5|   6|         Daniel Smith|      5|United States Vir...|\n",
      "|  6|   7|        Ashley Martin|      2|              Norway|\n",
      "|  7|   8|     Jamie Harrington|      4|               Chile|\n",
      "|  8|   9|          Mark Mendez|      3|             Georgia|\n",
      "|  9|  10|        Rebecca Fritz|      1|Central African R...|\n",
      "+---+----+---------------------+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.load(\"dataset_1e7.csv\", format=\"csv\", header = \"True\")\n",
    "df.show(10)\n",
    "#print('Schema is:')\n",
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- number_family_members: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- Covid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(fmt):\n",
    "    if fmt == \"json\":\n",
    "        df.write.json(\"file:///home/jovyan/work/fileformats/output/proto.json\")\n",
    "    elif fmt == \"csv\":\n",
    "        df.write.csv(\"file:///home/jovyan/work/fileformats/output/proto.csv\")\n",
    "    elif fmt == \"avro\":\n",
    "        df.write.avro(\"file:///home/jovyan/work/fileformats/proto.avro\")\n",
    "    elif fmt == \"parquet\":\n",
    "        df.write.parquet(\"file:///home/jovyan/work/fileformats/output/proto.parquet\")\n",
    "\n",
    "def write_2(fmt): # Using f-strings\n",
    "    df.write.format(f'{fmt}').save(f'file:///home/jovyan/work/fileformatsfile:///home/jovyan/work/fileformats/output/proto.{fmt}',header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n",
      "13.938474893569946\n",
      "\n",
      "\n",
      "json\n",
      "18.796042680740356\n",
      "\n",
      "\n",
      "parquet\n",
      "21.96593976020813\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "if os.path.exists(\"./output/\"):\n",
    "    shutil.rmtree(\"./output/\")\n",
    "    print('dirtee deleted')\n",
    "    os.makedirs(\"./output/\")\n",
    "    print('created empty dir \\n')\n",
    "\n",
    "for fmt in ['csv','json', 'parquet']:\n",
    "    print(fmt)\n",
    "    start = time.time()\n",
    "    write_2(fmt)\n",
    "    print(time.time() - start)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(fmt):\n",
    "    if fmt == \"json\":\n",
    "        sdf = spark.read.option(\"header\", \"true\").json(\"file:///home/jovyan/work/fileformats/output/proto.json\")\n",
    "    elif fmt == \"csv\":\n",
    "        sdf = spark.read.option(\"header\",\"true\").csv(\"file:///home/jovyan/work/fileformats/output/proto.csv\")\n",
    "    elif fmt == \"avro\":\n",
    "        sdf = spark.read.format(\"avro\").option(\"header\",\"true\").load(\"file:///home/jovyan/work/fileformats/output/proto.avro\")\n",
    "    elif fmt == \"parquet\":\n",
    "        sdf = spark.read.option(\"header\",\"true\").parquet(\"file:///home/jovyan/work/fileformats/output/proto.parquet\")\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n",
      "0.5632686614990234\n",
      "\n",
      "\n",
      "json\n",
      "5.866176128387451\n",
      "\n",
      "\n",
      "parquet\n",
      "0.38027310371398926\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fmt in ['csv','json', 'parquet']:\n",
    "    print(fmt)\n",
    "    start = time.time()\n",
    "    sdf = read(fmt)\n",
    "  #  sdf.printSchema()\n",
    "    print(time.time() - start)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve info from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert new record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@mike_82447/add-a-row-to-a-spark-dataframe-4e52f869c17b\n",
    "new_record = [['10000000','John Doe', '8', 'Netherlands', '0']]\n",
    "new_record_df = spark.createDataFrame(new_record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n",
      "0.5563492774963379\n",
      "\n",
      "\n",
      "json\n",
      "7.298802614212036\n",
      "\n",
      "\n",
      "parquet\n",
      "0.2456364631652832\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fmt in ['csv','json', 'parquet']:\n",
    "    print(fmt)\n",
    "    start = time.time()\n",
    "    sdf = read(fmt)\n",
    "    sdf.union(new_record_df)\n",
    "    print(time.time() - start)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               Covid|count|\n",
      "+--------------------+-----+\n",
      "|                Chad|40892|\n",
      "|            Paraguay|40814|\n",
      "|            Anguilla|40878|\n",
      "|               Macao|40950|\n",
      "|Heard Island and ...|40972|\n",
      "|               Yemen|40779|\n",
      "|             Senegal|40607|\n",
      "|             Tokelau|41085|\n",
      "|              Sweden|40679|\n",
      "|French Southern T...|40844|\n",
      "|            Kiribati|40461|\n",
      "|              Guyana|40817|\n",
      "|              Jersey|40852|\n",
      "|         Philippines|40738|\n",
      "|             Eritrea|41125|\n",
      "|      Norfolk Island|40816|\n",
      "|            Djibouti|40710|\n",
      "|               Tonga|41012|\n",
      "|            Malaysia|40709|\n",
      "|           Singapore|40789|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = read('csv')\n",
    "sdf.groupBy(\"Covid\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n",
      "+--------------------+-----+\n",
      "|               Covid|count|\n",
      "+--------------------+-----+\n",
      "|                Chad|40892|\n",
      "|            Paraguay|40814|\n",
      "|            Anguilla|40878|\n",
      "|               Macao|40950|\n",
      "|Heard Island and ...|40972|\n",
      "|               Yemen|40779|\n",
      "|             Senegal|40607|\n",
      "|             Tokelau|41085|\n",
      "|              Sweden|40679|\n",
      "|French Southern T...|40844|\n",
      "|            Kiribati|40461|\n",
      "|              Guyana|40817|\n",
      "|              Jersey|40852|\n",
      "|         Philippines|40738|\n",
      "|             Eritrea|41125|\n",
      "|      Norfolk Island|40816|\n",
      "|            Djibouti|40710|\n",
      "|               Tonga|41012|\n",
      "|            Malaysia|40709|\n",
      "|           Singapore|40789|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "5.210748910903931\n",
      "\n",
      "\n",
      "json\n",
      "+--------------------+-----+\n",
      "|               Covid|count|\n",
      "+--------------------+-----+\n",
      "|                Chad|40892|\n",
      "|            Anguilla|40878|\n",
      "|            Paraguay|40814|\n",
      "|               Macao|40950|\n",
      "|Heard Island and ...|40972|\n",
      "|               Yemen|40779|\n",
      "|             Senegal|40607|\n",
      "|              Sweden|40679|\n",
      "|             Tokelau|41085|\n",
      "|            Kiribati|40461|\n",
      "|French Southern T...|40844|\n",
      "|              Guyana|40817|\n",
      "|             Eritrea|41125|\n",
      "|              Jersey|40852|\n",
      "|         Philippines|40738|\n",
      "|               Tonga|41012|\n",
      "|      Norfolk Island|40816|\n",
      "|            Djibouti|40710|\n",
      "|           Singapore|40789|\n",
      "|            Malaysia|40709|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "6.529540538787842\n",
      "\n",
      "\n",
      "parquet\n",
      "+--------------------+-----+\n",
      "|               Covid|count|\n",
      "+--------------------+-----+\n",
      "|                Chad|40892|\n",
      "|            Anguilla|40878|\n",
      "|            Paraguay|40814|\n",
      "|               Macao|40950|\n",
      "|Heard Island and ...|40972|\n",
      "|               Yemen|40779|\n",
      "|             Senegal|40607|\n",
      "|              Sweden|40679|\n",
      "|             Tokelau|41085|\n",
      "|            Kiribati|40461|\n",
      "|French Southern T...|40844|\n",
      "|              Guyana|40817|\n",
      "|             Eritrea|41125|\n",
      "|              Jersey|40852|\n",
      "|         Philippines|40738|\n",
      "|               Tonga|41012|\n",
      "|      Norfolk Island|40816|\n",
      "|            Djibouti|40710|\n",
      "|           Singapore|40789|\n",
      "|            Malaysia|40709|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "1.4021618366241455\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fmt in ['csv','json', 'parquet']:\n",
    "    print(fmt)\n",
    "    sdf = read(fmt)\n",
    "   # sdf.printSchema()\n",
    "    start = time.time()\n",
    "    sdf.groupBy(\"Covid\").count().show()\n",
    "    print(time.time() - start)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to execute query\n",
    "def SQL_query(fmt, SQL_statement):\n",
    "    sdf=read(f'{fmt}')\n",
    "    sdf.createOrReplaceTempView(\"TempView\")\n",
    "    sqlDF = spark.sql(SQL_statement)\n",
    "    sqlDF.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n",
      "+-------+-------+\n",
      "|country|  count|\n",
      "+-------+-------+\n",
      "|      3|1668367|\n",
      "|      0|1665694|\n",
      "|      5|1666876|\n",
      "|      1|1666173|\n",
      "|      4|1668307|\n",
      "|      2|1664583|\n",
      "+-------+-------+\n",
      "\n",
      "5.957247257232666\n",
      "\n",
      "\n",
      "json\n",
      "+-------+-------+\n",
      "|country|  count|\n",
      "+-------+-------+\n",
      "|      3|1668367|\n",
      "|      0|1665694|\n",
      "|      5|1666876|\n",
      "|      1|1666173|\n",
      "|      4|1668307|\n",
      "|      2|1664583|\n",
      "+-------+-------+\n",
      "\n",
      "17.537051916122437\n",
      "\n",
      "\n",
      "parquet\n",
      "+-------+-------+\n",
      "|country|  count|\n",
      "+-------+-------+\n",
      "|      3|1668367|\n",
      "|      0|1665694|\n",
      "|      5|1666876|\n",
      "|      1|1666173|\n",
      "|      4|1668307|\n",
      "|      2|1664583|\n",
      "+-------+-------+\n",
      "\n",
      "1.9546408653259277\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL_statement = \"SELECT country, count(*) as count FROM TempView group by country\"\n",
    "\n",
    "for fmt in ['csv','json', 'parquet']:\n",
    "    print(fmt)\n",
    "    start = time.time()\n",
    "    SQL_query(fmt, SQL_statement)\n",
    "    print(time.time() - start)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n",
      "3.8470730781555176\n",
      "\n",
      "\n",
      "json\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n",
      "12.041115045547485\n",
      "\n",
      "\n",
      "parquet\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n",
      "0.6845920085906982\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL_statement = \"SELECT count(*) FROM TempView where country = 'Macao'\"\n",
    "for fmt in ['csv','json', 'parquet']:\n",
    "    print(fmt)\n",
    "    start = time.time()\n",
    "    SQL_query(fmt, SQL_statement)\n",
    "    print(time.time() - start)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n",
      "+---+----+---------------------+-------+-----+\n",
      "| id|name|number_family_members|country|Covid|\n",
      "+---+----+---------------------+-------+-----+\n",
      "|  1|   2|      Bradley Walters|      2| Mali|\n",
      "+---+----+---------------------+-------+-----+\n",
      "\n",
      "9.384071350097656\n",
      "\n",
      "\n",
      "json\n",
      "+-----+-------+---+----+---------------------+\n",
      "|Covid|country| id|name|number_family_members|\n",
      "+-----+-------+---+----+---------------------+\n",
      "| Mali|      2|  1|   2|      Bradley Walters|\n",
      "+-----+-------+---+----+---------------------+\n",
      "\n",
      "16.175256490707397\n",
      "\n",
      "\n",
      "parquet\n",
      "+---+----+---------------------+-------+-----+\n",
      "| id|name|number_family_members|country|Covid|\n",
      "+---+----+---------------------+-------+-----+\n",
      "|  1|   2|      Bradley Walters|      2| Mali|\n",
      "+---+----+---------------------+-------+-----+\n",
      "\n",
      "2.5878260135650635\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL_statement = \"SELECT * FROM TempView where id = 1\"\n",
    "for fmt in ['csv','json', 'parquet']:\n",
    "    print(fmt)\n",
    "    start = time.time()\n",
    "    SQL_query(fmt, SQL_statement)\n",
    "    print(time.time() - start)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min, max, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|max(number_family_members)|\n",
      "+--------------------------+\n",
      "|                Zoe Zuniga|\n",
      "+--------------------------+\n",
      "\n",
      "+--------------------------+\n",
      "|min(number_family_members)|\n",
      "+--------------------------+\n",
      "|              Aaron Abbott|\n",
      "+--------------------------+\n",
      "\n",
      "+----------------------------+\n",
      "|count(number_family_members)|\n",
      "+----------------------------+\n",
      "|                    10000000|\n",
      "+----------------------------+\n",
      "\n",
      "4.654228687286377\n"
     ]
    }
   ],
   "source": [
    "fmt = 'parquet'\n",
    "sdf=read(f'{fmt}')\n",
    "field = 'number_family_members'\n",
    "start = time.time()\n",
    "sdf.agg({field: \"max\"}).show(), sdf.agg({field: \"min\"}).show(), sdf.agg({field: \"count\"}).show()\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|max(number_family_members)|\n",
      "+--------------------------+\n",
      "|                Zoe Zuniga|\n",
      "+--------------------------+\n",
      "\n",
      "+--------------------------+\n",
      "|min(number_family_members)|\n",
      "+--------------------------+\n",
      "|              Aaron Abbott|\n",
      "+--------------------------+\n",
      "\n",
      "+----------------------------+\n",
      "|count(number_family_members)|\n",
      "+----------------------------+\n",
      "|                    10000000|\n",
      "+----------------------------+\n",
      "\n",
      "13.4062659740448\n"
     ]
    }
   ],
   "source": [
    "fmt = 'json'\n",
    "sdf=read(f'{fmt}')\n",
    "field = 'number_family_members'\n",
    "start = time.time()\n",
    "sdf.agg({field: \"max\"}).show(), sdf.agg({field: \"min\"}).show(), sdf.agg({field: \"count\"}).show()\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|max(number_family_members)|\n",
      "+--------------------------+\n",
      "|                Zoe Zuniga|\n",
      "+--------------------------+\n",
      "\n",
      "+--------------------------+\n",
      "|min(number_family_members)|\n",
      "+--------------------------+\n",
      "|              Aaron Abbott|\n",
      "+--------------------------+\n",
      "\n",
      "+----------------------------+\n",
      "|count(number_family_members)|\n",
      "+----------------------------+\n",
      "|                    10000000|\n",
      "+----------------------------+\n",
      "\n",
      "9.704328536987305\n"
     ]
    }
   ],
   "source": [
    "fmt = 'csv'\n",
    "sdf=read(f'{fmt}')\n",
    "field = 'number_family_members'\n",
    "start = time.time()\n",
    "sdf.agg({field: \"max\"}).show(), sdf.agg({field: \"min\"}).show(), sdf.agg({field: \"count\"}).show()\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output is 0.0 MB\n",
      "./output/proto.csv is 419.63 MB\n",
      "./output/proto.json is 1053.98 MB\n",
      "./output/proto.parquet is 185.52 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for r, d, f in os.walk('./output'):\n",
    "    size = sum(os.path.getsize(os.path.join(r,n)) for n in f) / 1048576\n",
    "    size = round(size,2)\n",
    "    print(\"{} is {} MB\".format(r, size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
